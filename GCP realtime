
## 1ï¸âƒ£ GCP Production Incident â€“ Pod CrashLoopBackOff

**Q:**
A production application on **GKE** suddenly goes into `CrashLoopBackOff`. What do you do?

**A (Real-time approach):**

> First, I check the pod logs using `kubectl logs` to identify application-level errors.
> Then I describe the pod to look for configuration or resource issues like failed liveness probes or OOMKills.
> I verify recent changes through GitOps history or CI/CD deployments.
> If needed, I roll back to the last stable version, communicate status to stakeholders, and later perform RCA to prevent recurrence.

---

## 2ï¸âƒ£ Terraform Drift in GCP

**Q:**
What is Terraform drift and how do you handle it?

**A:**

> Terraform drift occurs when resources in GCP are changed manually outside Terraform.
> I detect drift using `terraform plan`.
> In regulated environments, I restrict console access, enforce IaC-only changes via GitOps, and regularly reconcile state.
> If drift is legitimate, I update the Terraform code to match reality and reapply.

---

## 3ï¸âƒ£ Secure Landing Zone Design

**Q:**
How do you design a secure GCP landing zone?

**A:**

> I use a multi-project structure with separate projects for networking, security, and workloads.
> I enforce org policies, IAM least privilege, VPC Service Controls, private Google access, and centralized logging.
> Networking is done using shared VPCs with controlled subnet access.
> Everything is provisioned via Terraform to ensure consistency and auditability.

---

## 4ï¸âƒ£ Cloud Run vs GKE â€“ Real Choice

**Q:**
When would you choose Cloud Run over GKE?

**A:**

> I choose Cloud Run for stateless, event-driven workloads where I want minimal ops, fast scaling, and per-request billing.
> GKE is better when I need advanced networking, sidecars, stateful services, or fine-grained control.
> In practice, I often use both â€” Cloud Run for APIs and GKE for core platforms.

---

## 5ï¸âƒ£ CI/CD Pipeline Failure at Deployment Stage

**Q:**
A pipeline fails while deploying to GCP. What do you check?

**A:**

> I check the pipeline logs to identify whether itâ€™s authentication, permissions, or resource quota related.
> Then I validate service account roles, workload identity bindings, and Terraform state consistency.
> If itâ€™s environment-specific, I compare configs across dev, test, and prod to find drift.

---

## 6ï¸âƒ£ IAM Issue â€“ Access Denied in Production

**Q:**
A service suddenly gets `403 Access Denied`. Whatâ€™s your approach?

**A:**

> I identify which service account is failing and verify recent IAM changes.
> I check project-level and resource-level permissions.
> I avoid granting owner roles and instead assign minimum required predefined or custom roles.
> After fixing access, I add monitoring and alerts for IAM changes.

---

## 7ï¸âƒ£ GCP Networking â€“ Private & Secure Design

**Q:**
How do you design secure networking in GCP?

**A:**

> I use private subnets with no public IPs, Cloud NAT for outbound traffic, and internal load balancers.
> Firewall rules are restrictive by default.
> DNS is managed centrally, and sensitive services are protected using VPC Service Controls and private endpoints.

---

## 8ï¸âƒ£ Migration Scenario â€“ On-Prem to GCP

**Q:**
How would you migrate an on-prem application to GCP?

**A:**

> I first assess dependencies, data size, latency, and security requirements.
> I usually migrate infrastructure using Terraform, containerize applications where possible, and deploy to GKE or Cloud Run.
> Data is migrated using Database Migration Service or Storage Transfer Service.
> I validate performance before cutover and ensure rollback plans exist.

---

## 9ï¸âƒ£ Observability & Monitoring

**Q:**
How do you monitor GCP workloads?

**A:**

> I use Cloud Monitoring and Logging with custom metrics, alerts, and dashboards.
> For GKE, I monitor pod health, latency, error rates, and resource usage.
> Alerts are actionable and mapped to SLAs/SLOs to reduce alert fatigue.

---

## ðŸ”Ÿ Government / Enterprise Compliance Question

**Q:**
How do you ensure compliance in GCP?

**A:**

> I enforce policies using Organization Policies, IAM restrictions, audit logging, and encryption by default.
> Infrastructure is fully managed via Terraform and peer-reviewed.
> Access is logged, changes are traceable, and environments are isolated to meet government security standards.

---

## Bonus: Consultant-Style Closing Answer

If they ask **â€œWhy you?â€**, say:

> I combine strong hands-on GCP engineering skills with a consulting mindset.
> I focus on secure, scalable solutions, clear communication with stakeholders, and delivering long-term value rather than quick fixes.

---

## ðŸŒ How do you expose an application to the internet in GCP?

There are **multiple valid ways**, depending on **where your app is running**.

---

## ðŸ”¹ OPTION 1: Expose a VM-based App (Compute Engine)

### Steps (Real-world):

1. Deploy app on a **Compute Engine VM**
2. Assign an **External IP address**
3. Create **VPC firewall rules** (allow 80/443)
4. Ensure app listens on correct port
5. (Optional) Put a Load Balancer in front

### Interview Answer:

> I expose a VM-based application by assigning an **external IP** to the Compute Engine instance and creating **firewall rules** to allow inbound traffic on required ports like 80 or 443.
> For production, I place the VM behind an **HTTP(S) Load Balancer** for scalability and security.

---

## ðŸ”¹ OPTION 2: Expose a Container App Using Cloud Run (Best Practice)

### Steps:

1. Deploy container to **Cloud Run**
2. Set **ingress = allow all**
3. Allow **unauthenticated access**
4. GCP automatically exposes a public HTTPS URL

### Interview Answer:

> For serverless container workloads, I deploy the app on **Cloud Run** and allow unauthenticated access.
> GCP automatically provides a **secure public HTTPS endpoint**, handles scaling, and removes the need to manage infrastructure.

---

## ðŸ”¹ OPTION 3: Expose an App on GKE (Kubernetes)

### Ways:

* **Service type LoadBalancer**
* **Ingress with HTTP(S) Load Balancer** (recommended)

### Interview Answer:

> In GKE, I expose applications using a **Kubernetes Ingress** backed by a **GCP HTTP(S) Load Balancer**.
> This provides SSL termination, path-based routing, and auto-scaling across multiple pods.

---

## ðŸ”¹ OPTION 4: Expose App Using GCP Load Balancer (Production Grade)

### Architecture:

* Public **HTTP(S) Load Balancer**
* Backend: MIGs / GKE / Cloud Run
* SSL cert via Google-managed certificates

### Interview Answer:

> For production systems, I expose applications using a **global HTTP(S) Load Balancer**.
> It provides DDoS protection, SSL termination, health checks, and routes traffic to healthy backends.

---

## ðŸ”¹ OPTION 5: Secure Exposure (Private + Controlled Access)

### Used when:

* Internal apps
* Admin portals
* No public access

### Interview Answer:

> If the app should not be fully public, I expose it via **Identity-Aware Proxy (IAP)**, which authenticates users before granting access, without exposing the service directly to the internet.

---

## ðŸ§  Interview Comparison Summary

| Platform       | Best Exposure Method        |
| -------------- | --------------------------- |
| Compute Engine | External IP + Load Balancer |
| Cloud Run      | Auto HTTPS public URL       |
| GKE            | Ingress + HTTP(S) LB        |
| Internal App   | IAP or Internal LB          |

---

## â­ PERFECT FINAL INTERVIEW ANSWER (MEMORISE THIS)

> *To expose an application to the internet in GCP, I choose the method based on where the app is running.
> For VM-based apps, I use an external IP with firewall rules or a load balancer.
> For containers, I prefer Cloud Run or GKE with Ingress backed by an HTTP(S) Load Balancer.
> For secure access, I use Identity-Aware Proxy.
> In production, I always prioritize load balancers, HTTPS, and least-privilege access.*


